from chiscore import optimal_davies_pvalue, davies_pvalue


class StructLMM:
    r"""
    Structured linear mixed model that accounts for genotype-environment interactions.

    Let n be the number of samples.
    StructLMM [1] extends the conventional linear mixed model by including an
    additional per-individual effect term that accounts for genotype-environment
    interaction, which can be represented as an n√ó1 vector, ùõÉ.
    The model is given by

        ùê≤ = ùôºùõÇ + ùê†ùõΩ + ùê†‚äôùõÉ + ùêû + ùõÜ,

    where

        ùõΩ ‚àº ùìù(0, ùìã‚ÇÄ‚ãÖœÅ), ùõÉ ‚àº ùìù(ùüé, ùìã‚ÇÄ(1-œÅ)ùô¥ùô¥·µÄ), ùêû ‚àº ùìù(ùüé, ùìã‚ÇÅùöÜùöÜ·µÄ), and ùõÜ ‚àº ùìù(ùüé, ùìã‚ÇÇùô∏).

    The vector ùê≤ is the outcome, matrix ùôº contains the covariates, and vector ùê† is the
    genetic variant.
    The matrices ùô¥ and ùöÜ are generally the same, and represent the environment
    configuration for each sample.
    The parameters ùìã‚ÇÄ, ùìã‚ÇÅ, and ùìã‚ÇÇ are the overall variances.
    The parameter œÅ ‚àà [ùü∂, ùü∑] dictates the relevance of genotype-environment interaction
    versus the genotype effect alone.
    The term ùêû accounts for additive environment-only effects while ùõÜ accounts for
    noise effects.

    The above model is equivalent to

        ùê≤ = ùôºùõÇ + ùê†‚äôùõÉ + ùêû + ùõÜ,

    where

        ùõÉ ‚àº ùìù(ùüé, ùìã‚ÇÄ(œÅùüèùüè·µÄ + (1-œÅ)ùô¥ùô¥·µÄ)), ùêû ‚àº ùìù(ùüé, ùìã‚ÇÅùöÜùöÜ·µÄ), and ùõÜ ‚àº ùìù(ùüé, ùìã‚ÇÇùô∏).

    Its marginalised form is given by

        ùê≤ ‚àº ùìù(ùôºùõÇ, ùìã‚ÇÄùô≥(œÅùüèùüè·µÄ + (1-œÅ)ùô¥ùô¥·µÄ)ùô≥ + ùìã‚ÇÅùöÜùöÜ·µÄ + ùìã‚ÇÇùô∏),

    where ùô≥ = diag(ùê†).

    StructLMM method is used to perform two types of statistical tests.
    The association one compares the following hypothesis:

        ùìó‚ÇÄ: ùìã‚ÇÄ = 0
        ùìó‚ÇÅ: ùìã‚ÇÄ > 0

    ùìó‚ÇÄ denotes no genetic association, while ùìó‚ÇÅ models any genetic association.
    In particular, ùìó‚ÇÅ includes genotype-environment interaction as part of genetic
    association.
    The interaction test is slightly more complicated as the term ùê†ùõΩ is now considered
    a fixed one. In pratice, we include ùê† in the covariates matrix ùôº and set œÅ = 0.
    We refer to this modified model as the interaction model.
    The compared hypothesis are:

        ùìó‚ÇÄ: ùìã‚ÇÄ = 0 (given the interaction model)
        ùìó‚ÇÅ: ùìã‚ÇÄ > 0 (given the interaction model)

    Implementation
    --------------

    We employ the score-test statistic [2] for both tests

        ùëÑ = ¬Ωùê≤·µÄùôø(‚àÇùô∫)ùôøùê≤,

    where

        ùôø = ùô∫‚Åª¬π - ùô∫‚Åª¬πùôº(ùôº·µÄùô∫‚Åª¬πùôº)‚Åª¬πùôº·µÄùô∫‚Åª¬π and cov(ùê≤) = ùô∫

    for the REML-estimated parameters under the null hypothesis.
    The derivative is taken over the parameter being tested.

    Lets for now assume that œÅ is given.
    In practice, we have

        ùô∫·µ®  = ùìã‚ÇÄùô≥(œÅùüèùüè·µÄ + (1-œÅ)ùô¥ùô¥·µÄ)ùô≥ + ùìã‚ÇÅùöÜùöÜ·µÄ + ùìã‚ÇÇùô∏
        ‚àÇùô∫·µ® = ùô≥(œÅùüèùüè·µÄ + (1-œÅ)ùô¥ùô¥·µÄ)ùô≥

    for association test and

        ùô∫‚ÇÄ  = ùìã‚ÇÄùô≥ùô¥ùô¥·µÄùô≥ + ùìã‚ÇÅùöÜùöÜ·µÄ + ùìã‚ÇÇùô∏
        ‚àÇùô∫‚ÇÄ = ùô≥ùô¥ùô¥·µÄùô≥

    for interaction test, for parameters estimated via REML.
    The outcome distribution under null is

        ùê≤ ‚àº ùìù(ùôºùõÇ, ùìã‚ÇÅùöÜùöÜ·µÄ + ùìã‚ÇÇùô∏).

    It can be shown [2]_ that

        ùëÑ ‚àº ‚àë·µ¢ùúÜ·µ¢ùúí¬≤(1),

    where the weights ùúÜ·µ¢ are the non-zero eigenvalues of ¬Ω‚àöùôø(‚àÇùô∫)‚àöùôø.
    We employ modified Liu approximation to ùëÑ proposed [3] and modified in [4].

    References
    ----------
    .. [1] Moore, R., Casale, F. P., Bonder, M. J., Horta, D., Franke, L., Barroso,
       I., & Stegle, O. (2018). A linear mixed-model approach to study multivariate
       gene‚Äìenvironment interactions (p. 1). Nature Publishing Group.
    .. [2] Lippert, C., Xiang, J., Horta, D., Widmer, C., Kadie, C., Heckerman, D.,
       & Listgarten, J. (2014). Greater power and computational efficiency for
       kernel-based association testing of sets of genetic variants. Bioinformatics,
       30(22), 3206-3214.
    .. [3] Liu, H., Tang, Y., & Zhang, H. H. (2009). A new chi-square approximation
       to the distribution of non-negative definite quadratic forms in non-central
       normal variables. Computational Statistics & Data Analysis, 53(4), 853-856.
    .. [4] Lee, Seunggeun, Michael C. Wu, and Xihong Lin. "Optimal tests for rare
       variant effects in sequencing association studies." Biostatistics 13.4 (2012):
       762-775.
    """

    def __init__(self, y, M, E, W=None):
        from numpy import sqrt, asarray, atleast_2d
        from numpy_sugar import ddot

        self._y = atleast_2d(asarray(y, float).ravel()).T
        self._E = atleast_2d(asarray(E, float).T).T

        if W is None:
            self._W = self._E
        elif isinstance(W, tuple):
            # W must be an eigen-decomposition of ùöÜùöÜ·µÄ
            self._W = ddot(W[0], sqrt(W[1]))
        else:
            self._W = atleast_2d(asarray(W, float).T).T

        self._M = atleast_2d(asarray(M, float).T).T

        nsamples = len(self._y)
        if nsamples != self._M.shape[0]:
            raise ValueError("Number of samples mismatch between y and M.")

        if nsamples != self._E.shape[0]:
            raise ValueError("Number of samples mismatch between y and E.")

        if nsamples != self._W.shape[0]:
            raise ValueError("Number of samples mismatch between y and W.")

        self._lmm = None
        self._rhos = [0.0, 0.1 ** 2, 0.2 ** 2, 0.3 ** 2, 0.4 ** 2, 0.5 ** 2, 0.5, 0.999]

    def fit(self, verbose=True):
        from glimix_core.lmm import Kron2Sum

        self._lmm = Kron2Sum(self._y, [[1]], self._M, self._W, restricted=True)
        self._lmm.fit(verbose=verbose)
        self._covarparam0 = self._lmm.C0[0, 0]
        self._covarparam1 = self._lmm.C1[0, 0]

    def _P(self, v):
        """
        Let ùô∫ be the optimal covariance matrix under the null hypothesis.
        Given ùêØ, this method computes

            ùôøùêØ = ùô∫‚Åª¬πùêØ - ùô∫‚Åª¬πùôº(ùôº·µÄùô∫‚Åª¬πùôº)‚Åª¬πùôº·µÄùô∫‚Åª¬πùêØ.
        """
        from numpy_sugar.linalg import rsolve
        from scipy.linalg import cho_solve

        x = rsolve(self._lmm.covariance(), v)
        if self._lmm.X is not None:
            Lh = self._lmm._terms["Lh"]
            t = self._lmm.X @ cho_solve(Lh, self._lmm.M.T @ x)
            x -= rsolve(self._lmm.covariance(), t)

        return x

    def _score_stats(self, g, rhos):
        """
        Let ùô∫ be the optimal covariance matrix under the null hypothesis.
        For a given œÅ, the score-based test statistic is given by

            ùëÑ·µ® = ¬Ωùê≤·µÄùôø·µ®(‚àÇùô∫·µ®)ùôø·µ®ùê≤,

        where

            ‚àÇùô∫·µ® = ùô≥(œÅùüèùüè·µÄ + (1-œÅ)ùô¥ùô¥·µÄ)ùô≥

        and ùô≥ = diag(ùê†).
        """
        from numpy_sugar import ddot
        from numpy import zeros

        Q = zeros(len(rhos))
        DPy = ddot(g, self._P(self._y))
        s = DPy.sum()
        l = s * s
        DPyE = DPy.T @ self._E
        r = DPyE @ DPyE.T
        for i, rho in enumerate(rhos):
            Q[i] = (rho * l + (1 - rho) * r) / 2

        return Q

    def _score_stats_null_dist(self, g):
        """
        Under the null hypothesis, the score-based test statistic follows a weighted sum
        of random variables:

            ùëÑ ‚àº ‚àë·µ¢ùúÜ·µ¢œá¬≤(1),

        where ùúÜ·µ¢ are the non-zero eigenvalues of ¬Ω‚àöùôø(‚àÇùô∫)‚àöùôø.

        Note that

            ‚àÇùô∫·µ® = ùô≥(œÅùüèùüè·µÄ + (1-œÅ)ùô¥ùô¥·µÄ)ùô≥ = (œÅùê†ùê†·µÄ + (1-œÅ)ùô¥ÃÉùô¥ÃÉ·µÄ)

        for ùô¥ÃÉ = ùô≥ùô¥.
        By using SVD decomposition, one can show that the non-zero eigenvalues of ùöáùöá·µÄ
        are equal to the non-zero eigenvalues of ùöá·µÄùöá.
        Therefore, ùúÜ·µ¢ are the non-zero eigenvalues of

            ¬Ω[‚àöœÅùê† ‚àö(1-œÅ)ùô¥ÃÉ]ùôø[‚àöœÅùê† ‚àö(1-œÅ)ùô¥ÃÉ]·µÄ.

        """
        from numpy import empty
        from numpy.linalg import eigvalsh
        from math import sqrt
        from numpy_sugar import ddot

        Et = ddot(g, self._E)
        Pg = self._P(g)
        PEt = self._P(Et)

        gPg = g.T @ Pg
        EtPEt = Et.T @ PEt
        gPEt = g.T @ PEt

        n = Et.shape[1] + 1
        F = empty((n, n))

        lambdas = []
        for i in range(len(self._rhos)):
            rho = self._rhos[i]

            F[0, 0] = rho * gPg
            F[0, 1:] = sqrt(rho) * sqrt(1 - rho) * gPEt
            F[1:, 0] = F[0, 1:]
            F[1:, 1:] = (1 - rho) * EtPEt

            lambdas.append(eigvalsh(F) / 2)

        return lambdas

    def _score_stats_pvalue(self, Qs, lambdas):
        """
        Computes Pr(ùëÑ > q) for ùëÑ ‚àº ‚àë·µ¢ùúÜ·µ¢œá¬≤(1).

        Pr(ùëÑ > q) is the p-value for the score statistic.

        Parameters
        ----------
        Qs : array_like
            ùëÑ·µ® statistic.
        lambdas : array_like
            ùúÜ·µ¢ from the null distribution for each œÅ.
        """
        from numpy import stack

        return stack([_mod_liu(Q, lam) for Q, lam in zip(Qs, lambdas)], axis=0)

    def _qmin(self, pliumod):
        from numpy import zeros
        import scipy.stats as st

        # T statistic
        T = pliumod[:, 0].min()

        qmin = zeros(len(self._rhos))
        percentile = 1 - T
        for i in range(len(self._rhos)):
            q = st.chi2.ppf(percentile, pliumod[i, 3])
            mu_q = pliumod[i, 1]
            sigma_q = pliumod[i, 2]
            dof = pliumod[i, 3]
            qmin[i] = (q - dof) / (2 * dof) ** 0.5 * sigma_q + mu_q

        return qmin

    # SKAT
    def score_2dof_inter(self, X):
        from numpy import empty
        from numpy_sugar import ddot

        Q_rho = self._score_stats(X.ravel(), [0])

        g = X.ravel()
        Et = ddot(g, self._E)
        PEt = self._P(Et)

        EtPEt = Et.T @ PEt
        gPEt = g.T @ PEt

        n = Et.shape[1] + 1
        F = empty((n, n))

        F[0, 0] = 0
        F[0, 1:] = gPEt
        F[1:, 0] = F[0, 1:]
        F[1:, 1:] = EtPEt
        F /= 2

        return davies_pvalue(Q_rho[0], F)

    # SKAT-O
    def score_2dof_assoc(self, X):
        from numpy import trace, sum, where, empty
        from numpy.linalg import eigvalsh

        Q_rho = self._score_stats(X.ravel(), self._rhos)
        null_lambdas = self._score_stats_null_dist(X.ravel())
        pliumod = self._score_stats_pvalue(Q_rho, null_lambdas)
        qmin = self._qmin(pliumod)

        # 3. Calculate quantites that occur in null distribution
        Px1 = self._P(X)
        m = 0.5 * (X.T @ Px1)
        xoE = X * self._E
        PxoE = self._P(xoE)
        ETxPxE = 0.5 * (xoE.T @ PxoE)
        ETxPx1 = xoE.T @ Px1
        ETxPx11xPxE = 0.25 / m * (ETxPx1 @ ETxPx1.T)
        ZTIminusMZ = ETxPxE - ETxPx11xPxE
        eigh = eigvalsh(ZTIminusMZ)

        eta = ETxPx11xPxE @ ZTIminusMZ
        vareta = 4 * trace(eta)

        OneZTZE = 0.5 * (X.T @ PxoE)
        tau_top = OneZTZE @ OneZTZE.T
        tau_rho = empty(len(self._rhos))
        for i in range(len(self._rhos)):
            tau_rho[i] = self._rhos[i] * m + (1 - self._rhos[i]) / m * tau_top

        MuQ = sum(eigh)
        VarQ = sum(eigh ** 2) * 2 + vareta
        KerQ = sum(eigh ** 4) / (sum(eigh ** 2) ** 2) * 12
        Df = 12 / KerQ

        # 4. Integration
        T = pliumod[:, 0].min()
        pvalue = optimal_davies_pvalue(
            qmin, MuQ, VarQ, KerQ, eigh, vareta, Df, tau_rho, self._rhos, T
        )

        # Final correction to make sure that the p-value returned is sensible
        multi = 3
        if len(self._rhos) < 3:
            multi = 2
        idx = where(pliumod[:, 0] > 0)[0]
        pval = pliumod[:, 0].min() * multi
        if pvalue <= 0 or len(idx) < len(self._rhos):
            pvalue = pval
        if pvalue == 0:
            if len(idx) > 0:
                pvalue = pliumod[:, 0][idx].min()

        return pvalue


def _mod_liu(q, w):
    from chiscore import liu_sf

    (pv, dof_x, _, info) = liu_sf(q, w, [1] * len(w), [0] * len(w), True)
    return (pv, info["mu_q"], info["sigma_q"], dof_x)
